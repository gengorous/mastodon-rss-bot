import json
import feedparser
import requests
import os
import logging
from bs4 import BeautifulSoup  # BeautifulSoupã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è¿½åŠ 

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
with open("mastdon.json", "r", encoding="utf-8") as f:
    config = json.load(f)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾—
MASTODON_API_BASE = os.getenv("MASTODON_API_BASE", "https://mstdn.jp")  # ãƒã‚¹ãƒˆãƒ‰ãƒ³ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹URL
print(f"ğŸ” ç¾åœ¨ã® MASTODON_API_BASE: {MASTODON_API_BASE}")

# è¨˜äº‹ã®æŠ•ç¨¿ç®¡ç†

logging.basicConfig(level=logging.DEBUG)
POSTED_ARTICLES_FILE = "/persistent/posted_articles.json"
def load_posted_articles():
    """æŠ•ç¨¿æ¸ˆã¿è¨˜äº‹ã®ãƒªã‚¹ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€"""
    try:
        with open(POSTED_ARTICLES_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"ğŸ” èª­ã¿è¾¼ã‚“ã æŠ•ç¨¿æ¸ˆã¿è¨˜äº‹: {data}")  # ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
            return data
    except FileNotFoundError:
        print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€æ–°ã—ãä½œæˆã—ã¾ã™: {POSTED_ARTICLES_FILE}")  # ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        save_posted_articles([])  # âœ… ã“ã“ã§æ–°è¦ä½œæˆ
        return []
    except json.JSONDecodeError:
        print(f"âš ï¸ JSONã‚¨ãƒ©ãƒ¼ã€‚ç©ºã®ãƒªã‚¹ãƒˆã‚’è¿”ã—ã¾ã™: {POSTED_ARTICLES_FILE}")  # ğŸ” ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
        return []



def save_posted_articles(posted_articles):
    """æŠ•ç¨¿æ¸ˆã¿è¨˜äº‹ã®ãƒªã‚¹ãƒˆã‚’ JSON ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        print(f"âœ… è¨˜äº‹URLã‚’ä¿å­˜: {posted_articles}")  # ğŸ” ã“ã“ã§ä¿å­˜ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
        with open(POSTED_ARTICLES_FILE, "w", encoding="utf-8") as f:
            json.dump(posted_articles, f, ensure_ascii=False, indent=2)
            print(f"âœ… ä¿å­˜å®Œäº†: {POSTED_ARTICLES_FILE}")  # ğŸ” ã“ã“ã§ä¿å­˜å®Œäº†ã®ãƒ­ã‚°ã‚’å‡ºåŠ›
    except Exception as e:
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")  # ğŸ” ä¾‹å¤–ãŒç™ºç”Ÿã—ãŸå ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’å‡ºåŠ›



from urllib.parse import urlparse, urlunparse

def normalize_url(url):
    parsed = urlparse(url)
    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, '', '', ''))  # ã‚¯ã‚¨ãƒªã‚„ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤

def check_and_update_posted_articles(article_url):
    posted_articles = load_posted_articles()

    # URLã‚’æ­£è¦åŒ–
    normalized_url = normalize_url(article_url)
    print(f"ğŸ” æ­£è¦åŒ–ã•ã‚ŒãŸURL: {normalized_url}")

    if normalized_url in posted_articles:
        print(f"ğŸŸ¡ æ—¢ã«æŠ•ç¨¿æ¸ˆã¿: {normalized_url} â†’ ã‚¹ã‚­ãƒƒãƒ—")
        return False  # æ—¢ã«æŠ•ç¨¿æ¸ˆã¿

    # æ–°ã—ã„è¨˜äº‹ã‚’è¨˜éŒ²
    posted_articles.append(normalized_url)
    save_posted_articles(posted_articles)
    return True  # æŠ•ç¨¿OK



def extract_image_url(entry):
    """è¨˜äº‹ã®èª¬æ˜ã‚„ã‚µãƒãƒªãƒ¼ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡º"""
    content = getattr(entry, "description", None) or getattr(entry, "summary", None)
    
    if content:
        soup = BeautifulSoup(content, "html.parser")
        img_tag = soup.find("img")
        
        if img_tag and "src" in img_tag.attrs:
            return img_tag["src"]

    return None  # ç”»åƒãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    
from PIL import Image
import io

def resize_image(image_data, max_width=1280, max_height=1280):
    """ç”»åƒã‚’æŒ‡å®šã—ãŸæœ€å¤§å¹…ãƒ»é«˜ã•ã«ãƒªã‚µã‚¤ã‚º"""
    with Image.open(io.BytesIO(image_data)) as img:
        img.thumbnail((max_width, max_height))
        output = io.BytesIO()
        img.save(output, format="JPEG")
        return output.getvalue()


def fetch_latest_entry(feed_url):
    """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰æœ€æ–°ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—"""
    feed = feedparser.parse(feed_url)
    if feed.entries:
        entry = feed.entries[0]  # æœ€æ–°ã®æŠ•ç¨¿
        image_url = None

        # ç”»åƒURLã‚’æ¢ã™ï¼ˆRSSã®ä»•æ§˜ã«ã‚ˆã£ã¦è‰²ã€…è©¦ã™ï¼‰
        if "media_content" in entry and len(entry.media_content) > 0:
            image_url = entry.media_content[0]['url']
        elif "enclosures" in entry and len(entry.enclosures) > 0:
            image_url = entry.enclosures[0]['href']
        else:
            image_url = extract_image_url(entry)  # ã“ã“ã§ `extract_image_url()` ã‚’ä½¿ã†

        # å–å¾—ã—ãŸç”»åƒURLã‚’ãƒ­ã‚°ã«å‡ºã™
        if image_url:
            print(f"ğŸ–¼ ç”»åƒURL: {image_url}")
        else:
            print("âš  ç”»åƒURLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

        return entry, image_url
    return None, None


def upload_media(image_url, token):
    """ãƒã‚¹ãƒˆãƒ‰ãƒ³ã«ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ¡ãƒ‡ã‚£ã‚¢IDã‚’å–å¾—"""
    if not image_url:
        print("âš  ç”»åƒURLãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
        return None  # ç”»åƒãªã—ã§æŠ•ç¨¿

    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            "Referer": "https://mstdn.jp/"
        }
        response = requests.get(image_url, headers=headers)  

        print(f"ğŸ” HTTPãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")  
        print(f"ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {response.headers}")  
        print(f"ğŸ” ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(response.content)} ãƒã‚¤ãƒˆ")  

        if response.status_code != 200:
            print(f"âš  ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼: HTTP {response.status_code}")
            return None
        
        img_data = response.content

        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­æ•°ãƒã‚¤ãƒˆã‚’è¡¨ç¤ºã—ã¦ã€æœ¬å½“ã«JPEGã‹ç¢ºèª
        print(f"ğŸ” ç”»åƒãƒ‡ãƒ¼ã‚¿ï¼ˆå…ˆé ­20ãƒã‚¤ãƒˆï¼‰: {img_data[:20]}")

        if not img_data or len(img_data) == 0:
            print("âŒ ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒç©ºï¼")
            return None

        files = {'file': ('image.jpg', img_data, 'image/jpeg')}
        headers = {"Authorization": f"Bearer {token}"}

        response = requests.post(f"{MASTODON_API_BASE}/api/v2/media", headers=headers, files=files)

        print(f"ğŸ” ãƒã‚¹ãƒˆãƒ‰ãƒ³ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")  
        print(f"ğŸ” ãƒã‚¹ãƒˆãƒ‰ãƒ³ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {response.text}")  
        print(f"ğŸ” Mastodon æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿: {data}")

        if response.status_code == 200:
            media_id = response.json().get("id")
            print("âœ… ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ:", media_id)
            return media_id
        else:
            print("âŒ ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—:", response.status_code, response.text)
            print("ğŸ“ ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹:", response.text)
            return None
    except Exception as e:
        print("âŒ ç”»åƒå–å¾—ã‚¨ãƒ©ãƒ¼:", e)
        return None




def post_to_mastodon(status, mastodon_url, token, media_id=None):
    """ãƒã‚¹ãƒˆãƒ‰ãƒ³ã«æŠ•ç¨¿ï¼ˆBOTã®ãƒ«ãƒ¼ãƒ«ã«å¾“ã„ã€Œæœªåè¼‰ã€ã§æŠ•ç¨¿ï¼‰"""
    headers = {
    "Authorization": f"Bearer {token}",
    "User-Agent": "curl/8.10.1",  # `curl` ã® User-Agent ã‚’ãã®ã¾ã¾ä½¿ã†ï¼
    "Accept": "application/json",  # JSON ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¦æ±‚
    "Content-Type": "multipart/form-data",  # `curl` ã§ä½¿ã‚ã‚ŒãŸ `Content-Type` ã«åˆã‚ã›ã‚‹
}

    data = {
        "status": status,
        "visibility": "unlisted"  # âœ… æœªåè¼‰ã«ã™ã‚‹ã“ã¨ã§ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ã«ã¯è¦‹ãˆã‚‹
    }
    if media_id:
        data["media_ids[]"] = [media_id]  # ç”»åƒã‚’æ·»ä»˜

    # ğŸ” ã“ã“ã§URLã‚’ç¢ºèªï¼
    print(f"ğŸ” é€ä¿¡ã™ã‚‹ Mastodon API URL: {mastodon_url}")

    response = requests.post(
        mastodon_url,
        headers=headers,
        data=data,
        allow_redirects=False,  # ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã‚’é˜²ã
        verify=False 
    )

    print(f"ğŸ” ãƒã‚¹ãƒˆãƒ‰ãƒ³æŠ•ç¨¿ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
    print(f"ğŸ” ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {response.headers}")
    print(f"ğŸ” ãƒã‚¹ãƒˆãƒ‰ãƒ³æŠ•ç¨¿ãƒ¬ã‚¹ãƒãƒ³ã‚¹å†…å®¹: {response.text}")

    if response.status_code == 200:
        print("âœ… æŠ•ç¨¿æˆåŠŸ:", status)
    else:
        print("âŒ æŠ•ç¨¿å¤±æ•—:", response.status_code)
        print("ğŸ“ ãƒã‚¹ãƒˆãƒ‰ãƒ³ã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:", response.text)



# `image_url` ã¯ `fetch_latest_entry()` ã§å–å¾—ã•ã‚Œã‚‹
def main():
    for site in config["sites"]:
        print(f"å‡¦ç†ä¸­: {site['name']}")
        
        entry, image_url = fetch_latest_entry(site["rss_url"])  # ã“ã“ã§ `image_url` ã‚’å–å¾—
        
        if entry:
            # æŠ•ç¨¿æ¸ˆã¿ãƒã‚§ãƒƒã‚¯
            if not check_and_update_posted_articles(entry.link):
                continue  # æŠ•ç¨¿æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
            
            # ç”»åƒãŒã‚ã‚‹å ´åˆã®ã¿å–å¾—ï¼†ãƒªã‚µã‚¤ã‚ºå‡¦ç†ã‚’å®Ÿè¡Œ
            resized_image_data = None
            if image_url:
                response = requests.get(image_url)
                if response.status_code == 200:
                    resized_image_data = resize_image(response.content)

            # æ–°ã—ã„è¨˜äº‹ã®æŠ•ç¨¿
            status = f"{site['title']}\n{entry.title}\n{entry.link}"
            media_id = None
            if resized_image_data:
                media_id = upload_media(image_url, site["mastodon_token"])  # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            post_to_mastodon(status, site["mastodon_url"], site["mastodon_token"], media_id)



if __name__ == "__main__":
    main()

